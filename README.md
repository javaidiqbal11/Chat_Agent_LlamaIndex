# ğŸ§  Chat Agent with LlamaIndex

A powerful **AI-powered conversational agent** using [LlamaIndex](https://github.com/jerryjliu/llama_index), [LangChain](https://github.com/langchain-ai/langchain), [ChromaDB](https://www.trychroma.com/), and [Gradio](https://gradio.app/) for document-based QA, contextual chat, and knowledge retrieval.

This project demonstrates how to build an **RAG (Retrieval-Augmented Generation)** system using your own documents.

---

## âœ¨ Features

* âœ… Document upload and indexing via LlamaIndex
* ğŸ§  Semantic search over your knowledge base
* ğŸ“‚ ChromaDB for fast vector storage and retrieval
* ğŸ’¬ OpenAI LLM for answering user queries with context
* ğŸ§ª Gradio-based interactive UI
* ğŸ” Secure API key handling using `.env`

---

## ğŸ“ Project Structure

```
Chat_Agent_LlamaIndex/
â”‚
â”œâ”€â”€ docs/                          # Directory to hold uploaded documents
â”‚
â”œâ”€â”€ app.py                         # FastAPI app (can be expanded for API access)
â”œâ”€â”€ ui.py                          # Gradio app for chat interface
â”œâ”€â”€ index_utils.py                 # LlamaIndex functions: load, build, query index
â”œâ”€â”€ prompt_helper.py               # Prompt tuning and configuration
â”‚
â”œâ”€â”€ .env                           # API key config
â”œâ”€â”€ requirements.txt               # All dependencies
â””â”€â”€ README.md                      # You are here!
```

---

## ğŸ§ª Tech Stack

| Tool           | Role                               |
| -------------- | ---------------------------------- |
| **LlamaIndex** | Converts documents to vector index |
| **ChromaDB**   | Vector database for fast retrieval |
| **LangChain**  | Language model orchestration       |
| **OpenAI**     | LLM provider (e.g., GPT-4)         |
| **Gradio**     | Frontend chat UI                   |
| **FastAPI**    | Backend setup for API integration  |

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/javaidiqbal11/Chat_Agent_LlamaIndex.git
cd Chat_Agent_LlamaIndex
```

### 2. Set Up Virtual Environment (Optional but Recommended)

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

### 4. Add Your OpenAI Key

Create a `.env` file in the root folder and add:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

---

## ğŸš€ Running the App

### Start Gradio App

```bash
python ui.py
```

* The app will launch in your browser.
* Upload `.pdf`, `.docx`, or `.txt` files to populate the knowledge base.
* Ask questions in natural language based on the uploaded documents.

> You can modify Gradio port and config in `ui.py`.

---

## ğŸ” How It Works

1. **Document Upload:**

   * Uploaded files are parsed and chunked.
   * Text is embedded using OpenAI embeddings.

2. **Index Creation:**

   * `LlamaIndex` builds a vector index over the text chunks.
   * Index is stored in ChromaDB for efficient vector search.

3. **Query Handling:**

   * User query is embedded and matched to relevant chunks.
   * A prompt is constructed and passed to OpenAI's GPT model.
   * Final answer is returned in a chat format.

---

## ğŸ› ï¸ Core Components

### `index_utils.py`

* `build_index(doc_folder)` â†’ builds index from documents
* `load_index()` â†’ loads saved index from disk
* `query_index(index, query)` â†’ gets response to user query

### `prompt_helper.py`

Customizes:

* Prompt length
* Chunk overlap
* Maximum input/output tokens

You can modify these for fine-tuning performance and cost.

---

## ğŸ“‚ Document Support

Supports:

* `.pdf`
* `.docx`
* `.txt`

You can easily extend support in `index_utils.py`.

---

## ğŸ§ª Sample Query Flow

```text
> Upload: telecom_policy.pdf

> Query: What are the charges for international roaming?

> Output: According to section 3 of telecom_policy.pdf, international roaming charges are...
```

---

## ğŸ§± Built With

* [LlamaIndex](https://github.com/jerryjliu/llama_index)
* [LangChain](https://github.com/langchain-ai/langchain)
* [ChromaDB](https://www.trychroma.com/)
* [OpenAI GPT-4](https://platform.openai.com/)
* [Gradio](https://www.gradio.app/)
* [FastAPI](https://fastapi.tiangolo.com/)

---

## ğŸ“Œ Future Enhancements (Suggestions)

* âœ… Add MongoDB/FAISS as optional storage backends
* âœ… Support chat history (memory)
* âœ… Deploy on HuggingFace Spaces or AWS
* âœ… Add authentication layer for document upload
* âœ… Add LangSmith tracing/debugging

---

## ğŸ“œ License

This project is licensed under the MIT License. See [`LICENSE`](LICENSE) for details.

---

## ğŸ¤ Contribution

PRs and feedback are welcome! Open an issue or fork the repo to start contributing.

